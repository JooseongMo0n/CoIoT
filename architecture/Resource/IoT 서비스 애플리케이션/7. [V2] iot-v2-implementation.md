# 스마트홈 IoT V2 구현 가이드 - AI 스피커와 지능형 자동화

## 1. V2 개요 및 아키텍처 업그레이드

### 1.1 V2 핵심 목표
- **음성 우선 인터페이스**: AI 스피커를 통한 자연스러운 상호작용
- **로컬 AI 처리**: 프라이버시 보호와 저지연 응답
- **지능형 자동화**: 컨텍스트 인식 및 학습 기반 자동화
- **표준 프로토콜 지원**: Matter/Thread 통합

### 1.2 시스템 아키텍처 변경사항
```yaml
V1 → V2 주요 변경:
  - 음성 처리 레이어 추가
  - 엣지 AI 서버 도입 (로컬 추론)
  - 이벤트 기반 → 이벤트 + 스트림 하이브리드
  - 단순 규칙 → ML 기반 자동화
  - MQTT only → MQTT + Matter/Thread
```

## 2. AI 스피커 하드웨어 구현

### 2.1 ESP32-S3 기반 AI 스피커 펌웨어

```cpp
// firmware/ai-speaker/main.ino
#include <ESP_I2S.h>
#include <WiFi.h>
#include <PubSubClient.h>
#include <Porcupine.h>
#include <FastLED.h>
#include <esp_task_wdt.h>

// 하드웨어 핀 정의
#define I2S_WS 15
#define I2S_SD 13
#define I2S_SCK 2
#define I2S_SD_OUT 21
#define LED_PIN 5
#define NUM_LEDS 12

// 오디오 설정
#define SAMPLE_RATE 16000
#define AUDIO_BUFFER_SIZE 512
#define RECORD_DURATION 5000  // 5초

// 상태 정의
enum SpeakerState {
  IDLE,
  LISTENING_WAKE_WORD,
  RECORDING_COMMAND,
  PROCESSING,
  SPEAKING
};

// 전역 변수
I2SClass I2S;
CRGB leds[NUM_LEDS];
WiFiClient espClient;
PubSubClient mqtt(espClient);
SpeakerState currentState = LISTENING_WAKE_WORD;

// Porcupine 설정
static pv_porcupine_t *porcupine = NULL;
static const char *ACCESS_KEY = "YOUR_PORCUPINE_KEY";
static int16_t pcmBuffer[512];

// 오디오 버퍼 (PSRAM 사용)
int16_t *recordBuffer = nullptr;
size_t recordIndex = 0;
const size_t maxRecordSize = SAMPLE_RATE * RECORD_DURATION / 1000;

void setup() {
  Serial.begin(115200);
  
  // PSRAM 초기화
  if (psramFound()) {
    recordBuffer = (int16_t*)ps_malloc(maxRecordSize * sizeof(int16_t));
    Serial.println("PSRAM initialized for audio buffer");
  }
  
  // LED 초기화
  FastLED.addLeds<WS2812B, LED_PIN, GRB>(leds, NUM_LEDS);
  FastLED.setBrightness(50);
  
  // I2S 마이크 초기화
  I2S.setAllPins(I2S_SCK, I2S_WS, I2S_SD, I2S_SD_OUT, I2S_SD);
  if (!I2S.begin(I2S_MODE_STD, SAMPLE_RATE, I2S_DATA_BIT_WIDTH_16BIT, I2S_SLOT_MODE_MONO)) {
    Serial.println("Failed to initialize I2S!");
    while (1);
  }
  
  // WiFi 연결
  connectWiFi();
  
  // MQTT 설정
  mqtt.setServer("192.168.1.100", 1883);
  mqtt.setCallback(mqttCallback);
  
  // Porcupine 초기화 (Wake Word Detection)
  initializePorcupine();
  
  // 멀티태스킹 설정
  xTaskCreatePinnedToCore(audioProcessingTask, "AudioTask", 8192, NULL, 1, NULL, 0);
  xTaskCreatePinnedToCore(ledAnimationTask, "LEDTask", 4096, NULL, 1, NULL, 1);
}

void initializePorcupine() {
  // "Hey Home" 웨이크 워드 초기화
  const char *keyword_paths = "/wake_word/hey_home_ko.ppn";
  const float sensitivity = 0.5f;
  
  pv_status_t status = pv_porcupine_init(
    ACCESS_KEY,
    1,  // 키워드 개수
    &keyword_paths,
    &sensitivity,
    &porcupine
  );
  
  if (status != PV_STATUS_SUCCESS) {
    Serial.println("Failed to initialize Porcupine");
  }
}

void audioProcessingTask(void *parameter) {
  while (true) {
    switch (currentState) {
      case LISTENING_WAKE_WORD:
        detectWakeWord();
        break;
        
      case RECORDING_COMMAND:
        recordAudioCommand();
        break;
        
      case PROCESSING:
        // 처리 중 대기
        vTaskDelay(100 / portTICK_PERIOD_MS);
        break;
        
      case SPEAKING:
        // TTS 재생 중
        vTaskDelay(100 / portTICK_PERIOD_MS);
        break;
        
      default:
        currentState = LISTENING_WAKE_WORD;
    }
    
    // Watchdog 타이머 리셋
    esp_task_wdt_reset();
  }
}

void detectWakeWord() {
  // 오디오 읽기
  size_t bytesRead = I2S.readBytes((char*)pcmBuffer, sizeof(pcmBuffer));
  int samplesRead = bytesRead / 2;
  
  if (samplesRead == pv_porcupine_frame_length()) {
    int32_t keyword_index = -1;
    pv_status_t status = pv_porcupine_process(porcupine, pcmBuffer, &keyword_index);
    
    if (status == PV_STATUS_SUCCESS && keyword_index >= 0) {
      Serial.println("Wake word detected!");
      currentState = RECORDING_COMMAND;
      recordIndex = 0;
      
      // MQTT로 상태 전송
      mqtt.publish("speaker/status", "{\"state\":\"listening\"}");
      
      // 피드백 사운드 재생
      playBeep(1000, 100);  // 1kHz, 100ms
    }
  }
}

void recordAudioCommand() {
  if (recordIndex < maxRecordSize) {
    size_t bytesRead = I2S.readBytes(
      (char*)(recordBuffer + recordIndex), 
      min(1024, (maxRecordSize - recordIndex) * 2)
    );
    recordIndex += bytesRead / 2;
    
    // 음성 활동 감지 (VAD)
    if (detectSilence(recordBuffer + recordIndex - 512, 512)) {
      // 침묵 감지 시 녹음 종료
      finishRecording();
    }
  } else {
    // 최대 녹음 시간 도달
    finishRecording();
  }
}

void finishRecording() {
  currentState = PROCESSING;
  
  // 오디오 데이터를 Base64로 인코딩
  String encodedAudio = base64Encode(recordBuffer, recordIndex * 2);
  
  // MQTT로 오디오 전송
  StaticJsonDocument<1024> doc;
  doc["type"] = "audio_command";
  doc["speaker_id"] = WiFi.macAddress();
  doc["audio_format"] = "pcm_s16le";
  doc["sample_rate"] = SAMPLE_RATE;
  doc["audio_data"] = encodedAudio;  // 실제로는 청크로 나눠서 전송
  
  String jsonString;
  serializeJson(doc, jsonString);
  
  // 큰 데이터는 청크로 나눠서 전송
  sendLargePayload("speaker/audio", jsonString);
  
  // 처리 대기
  playBeep(800, 50);  // 처리 중 비프음
}

bool detectSilence(int16_t* buffer, int length) {
  // 간단한 에너지 기반 VAD
  int64_t energy = 0;
  for (int i = 0; i < length; i++) {
    energy += abs(buffer[i]);
  }
  
  float avgEnergy = energy / (float)length;
  return avgEnergy < 500;  // 임계값
}

void playTTS(const uint8_t* audioData, size_t length) {
  currentState = SPEAKING;
  
  // I2S 스피커로 오디오 출력
  size_t bytesWritten = 0;
  I2S.writeBytes(audioData, length, &bytesWritten);
  
  // 완료 후 대기 상태로
  currentState = LISTENING_WAKE_WORD;
}

void ledAnimationTask(void *parameter) {
  while (true) {
    switch (currentState) {
      case LISTENING_WAKE_WORD:
        // 천천히 숨쉬는 효과
        breathingEffect(CRGB::Blue);
        break;
        
      case RECORDING_COMMAND:
        // 빠른 회전 효과
        spinningEffect(CRGB::Green);
        break;
        
      case PROCESSING:
        // 펄싱 효과
        pulsingEffect(CRGB::Yellow);
        break;
        
      case SPEAKING:
        // 음성 레벨에 따른 효과
        speakingEffect(CRGB::Cyan);
        break;
    }
    
    FastLED.show();
    vTaskDelay(30 / portTICK_PERIOD_MS);
  }
}

void breathingEffect(CRGB color) {
  static uint8_t brightness = 0;
  static int8_t delta = 1;
  
  brightness += delta;
  if (brightness == 0 || brightness == 100) delta = -delta;
  
  fill_solid(leds, NUM_LEDS, color);
  FastLED.setBrightness(brightness);
}

void spinningEffect(CRGB color) {
  static uint8_t pos = 0;
  fadeToBlackBy(leds, NUM_LEDS, 20);
  leds[pos] = color;
  leds[(pos + NUM_LEDS/2) % NUM_LEDS] = color;
  pos = (pos + 1) % NUM_LEDS;
}

void mqttCallback(char* topic, byte* payload, unsigned int length) {
  StaticJsonDocument<512> doc;
  deserializeJson(doc, payload, length);
  
  String command = doc["command"];
  
  if (command == "play_tts") {
    // TTS 오디오 수신 및 재생
    const char* audioB64 = doc["audio"];
    size_t audioLen;
    uint8_t* audioData = base64Decode(audioB64, &audioLen);
    playTTS(audioData, audioLen);
    free(audioData);
  }
}
```

### 2.2 음성 처리 백엔드 서비스

```javascript
// backend/src/services/voiceService.js
const { Readable } = require('stream');
const { spawn } = require('child_process');
const EventEmitter = require('events');
const fs = require('fs').promises;
const path = require('path');

class VoiceService extends EventEmitter {
  constructor() {
    super();
    this.whisperModel = null;
    this.piperVoice = null;
    this.nlpService = null;
    this.initializeModels();
  }

  async initializeModels() {
    // Whisper 모델 초기화
    await this.loadWhisperModel();
    
    // Piper TTS 초기화
    await this.loadPiperVoice();
    
    // NLP 서비스 초기화
    this.nlpService = require('./nlpService');
  }

  async loadWhisperModel() {
    // Faster Whisper를 사용한 빠른 추론
    const modelPath = path.join(__dirname, '../../../models/whisper-small-ko');
    
    // Python 서브프로세스로 Whisper 실행
    this.whisperProcess = spawn('python', [
      path.join(__dirname, '../python/whisper_service.py'),
      '--model', modelPath,
      '--language', 'ko',
      '--device', 'cpu',
      '--compute_type', 'int8'
    ]);

    this.whisperProcess.stdout.on('data', (data) => {
      const result = JSON.parse(data.toString());
      this.emit('transcription', result);
    });
  }

  async loadPiperVoice() {
    // Piper TTS 한국어 음성 로드
    const voicePath = path.join(__dirname, '../../../models/piper/ko_KR-kss-medium.onnx');
    
    this.piperProcess = spawn('piper', [
      '--model', voicePath,
      '--output-raw',
      '--quiet'
    ]);
  }

  async processAudioCommand(audioData, format = 'pcm_s16le', sampleRate = 16000) {
    try {
      // 1. 오디오 데이터 전처리
      const processedAudio = await this.preprocessAudio(audioData, format, sampleRate);
      
      // 2. STT (Speech-to-Text)
      const transcription = await this.transcribeAudio(processedAudio);
      console.log('Transcription:', transcription.text);
      
      // 3. NLU (Natural Language Understanding)
      const intent = await this.nlpService.processIntent(transcription.text);
      console.log('Intent:', intent);
      
      // 4. 명령 실행
      const result = await this.executeCommand(intent);
      
      // 5. 응답 생성
      const response = await this.generateResponse(intent, result);
      
      // 6. TTS (Text-to-Speech)
      const audioResponse = await this.synthesizeSpeech(response.text);
      
      return {
        transcription: transcription.text,
        intent,
        response: response.text,
        audio: audioResponse
      };
      
    } catch (error) {
      console.error('Voice processing error:', error);
      
      // 에러 시 기본 응답
      const errorResponse = "죄송합니다. 명령을 이해하지 못했습니다.";
      const errorAudio = await this.synthesizeSpeech(errorResponse);
      
      return {
        error: error.message,
        response: errorResponse,
        audio: errorAudio
      };
    }
  }

  async preprocessAudio(audioData, format, sampleRate) {
    // 노이즈 제거 및 정규화
    // 실제 구현에서는 Sox 또는 FFmpeg 사용
    return audioData;
  }

  async transcribeAudio(audioBuffer) {
    return new Promise((resolve, reject) => {
      // Whisper 프로세스로 오디오 전송
      const input = {
        audio: audioBuffer.toString('base64'),
        options: {
          beam_size: 5,
          best_of: 5,
          temperature: 0
        }
      };
      
      this.whisperProcess.stdin.write(JSON.stringify(input) + '\n');
      
      // 타임아웃 설정
      const timeout = setTimeout(() => {
        reject(new Error('Transcription timeout'));
      }, 10000);
      
      this.once('transcription', (result) => {
        clearTimeout(timeout);
        resolve(result);
      });
    });
  }

  async synthesizeSpeech(text) {
    return new Promise((resolve, reject) => {
      const chunks = [];
      
      // Piper로 텍스트 전송
      this.piperProcess.stdin.write(text + '\n');
      
      // 오디오 데이터 수집
      const onData = (chunk) => {
        chunks.push(chunk);
      };
      
      this.piperProcess.stdout.on('data', onData);
      
      // 종료 시그널 대기
      setTimeout(() => {
        this.piperProcess.stdout.removeListener('data', onData);
        const audioBuffer = Buffer.concat(chunks);
        resolve(audioBuffer);
      }, 2000);
    });
  }

  async executeCommand(intent) {
    const { action, entities } = intent;
    
    switch (action) {
      case 'control_device':
        return await this.deviceController.control(
          entities.device,
          entities.action,
          entities.value
        );
        
      case 'query_status':
        return await this.deviceController.getStatus(entities.device);
        
      case 'activate_scene':
        return await this.sceneController.activate(entities.scene);
        
      case 'set_automation':
        return await this.automationController.create(intent);
        
      default:
        throw new Error(`Unknown action: ${action}`);
    }
  }

  async generateResponse(intent, result) {
    // 컨텍스트 기반 응답 생성
    const templates = {
      control_device: {
        success: "${device}을(를) ${action}했습니다.",
        failure: "${device} 제어에 실패했습니다."
      },
      query_status: {
        online: "${device}의 현재 ${property}은(는) ${value}입니다.",
        offline: "${device}이(가) 오프라인 상태입니다."
      },
      activate_scene: {
        success: "${scene} 씬을 활성화했습니다.",
        failure: "${scene} 씬을 찾을 수 없습니다."
      }
    };
    
    const template = templates[intent.action];
    const status = result.success ? 'success' : 'failure';
    
    let response = template[status] || template.success;
    
    // 템플릿 변수 치환
    Object.keys(intent.entities).forEach(key => {
      response = response.replace(`\${${key}}`, intent.entities[key]);
    });
    
    Object.keys(result).forEach(key => {
      response = response.replace(`\${${key}}`, result[key]);
    });
    
    return { text: response };
  }
}

// Python Whisper 서비스
// backend/src/python/whisper_service.py
```

```python
#!/usr/bin/env python3
import sys
import json
import base64
import numpy as np
from faster_whisper import WhisperModel
import argparse

class WhisperService:
    def __init__(self, model_path, language='ko', device='cpu', compute_type='int8'):
        self.model = WhisperModel(
            model_path,
            device=device,
            compute_type=compute_type
        )
        self.language = language
    
    def transcribe(self, audio_data):
        # Base64 디코딩
        audio_bytes = base64.b64decode(audio_data)
        audio_array = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
        
        # 음성 인식
        segments, info = self.model.transcribe(
            audio_array,
            language=self.language,
            beam_size=5,
            best_of=5,
            temperature=0
        )
        
        # 결과 조합
        text = " ".join([segment.text for segment in segments])
        
        return {
            "text": text,
            "language": info.language,
            "duration": info.duration
        }
    
    def run(self):
        """stdin으로부터 요청을 받아 처리"""
        while True:
            try:
                line = sys.stdin.readline()
                if not line:
                    break
                
                request = json.loads(line)
                audio_data = request['audio']
                
                result = self.transcribe(audio_data)
                
                # stdout으로 결과 전송
                print(json.dumps(result))
                sys.stdout.flush()
                
            except Exception as e:
                error_result = {"error": str(e)}
                print(json.dumps(error_result))
                sys.stdout.flush()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', required=True)
    parser.add_argument('--language', default='ko')
    parser.add_argument('--device', default='cpu')
    parser.add_argument('--compute_type', default='int8')
    
    args = parser.parse_args()
    
    service = WhisperService(
        args.model,
        args.language,
        args.device,
        args.compute_type
    )
    
    service.run()
```

### 2.3 자연어 이해 (NLU) 서비스

```javascript
// backend/src/services/nlpService.js
const { loadModel } = require('./modelLoader');
const natural = require('natural');
const { NER } = require('korean-ner');

class NLPService {
  constructor() {
    this.intentClassifier = null;
    this.entityExtractor = null;
    this.deviceAliases = new Map();
    this.initialize();
  }

  async initialize() {
    // 의도 분류 모델 로드
    this.intentClassifier = await loadModel('intent_classifier.onnx');
    
    // 개체명 인식기 초기화
    this.entityExtractor = new NER();
    
    // 디바이스 별칭 로드
    await this.loadDeviceAliases();
    
    // 커스텀 패턴 정의
    this.definePatterns();
  }

  definePatterns() {
    // 디바이스 제어 패턴
    this.patterns = {
      control_device: [
        /(.+?)\s*(를|을)?\s*(켜|꺼|올려|내려|설정)/,
        /(.+?)\s*(온도를?|밝기를?|속도를?)?\s*(\d+)(도|%|단계)?로?\s*설정/,
        /(.+?)\s*(를|을)?\s*(킬|오프|온|활성화|비활성화)/
      ],
      query_status: [
        /(.+?)\s*(의)?\s*(상태|온도|습도|밝기)(가|는)?\s*어때/,
        /(.+?)\s*(이|가)?\s*켜져?\s*있/,
        /현재\s*(.+?)\s*(온도|습도|상태)/
      ],
      activate_scene: [
        /(.+?)\s*(모드|씬|장면)(으로|을)?\s*(설정|변경|활성화)/,
        /(.+?)\s*(모드|씬|장면)\s*시작/
      ],
      create_automation: [
        /(.+?)(이|가)?\s*(.+?)되면\s*(.+?)(을|를)?\s*(.+)/,
        /만약\s*(.+?)면\s*(.+)/
      ]
    };
  }

  async processIntent(text) {
    try {
      // 1. 텍스트 정규화
      const normalizedText = this.normalizeText(text);
      
      // 2. 의도 분류
      const intent = await this.classifyIntent(normalizedText);
      
      // 3. 엔티티 추출
      const entities = await this.extractEntities(normalizedText, intent);
      
      // 4. 컨텍스트 보강
      const enrichedIntent = await this.enrichWithContext(intent, entities);
      
      return enrichedIntent;
      
    } catch (error) {
      console.error('NLP processing error:', error);
      return {
        action: 'unknown',
        confidence: 0,
        entities: {},
        original_text: text
      };
    }
  }

  normalizeText(text) {
    // 한국어 정규화
    return text
      .toLowerCase()
      .replace(/[~!@#$%^&*()_+|<>?:{}]/g, '')
      .replace(/\s+/g, ' ')
      .trim();
  }

  async classifyIntent(text) {
    // 패턴 매칭 우선
    for (const [intent, patterns] of Object.entries(this.patterns)) {
      for (const pattern of patterns) {
        if (pattern.test(text)) {
          return {
            action: intent,
            confidence: 0.9,
            method: 'pattern'
          };
        }
      }
    }
    
    // ML 모델 사용
    const features = this.extractFeatures(text);
    const prediction = await this.intentClassifier.predict(features);
    
    return {
      action: prediction.label,
      confidence: prediction.confidence,
      method: 'ml'
    };
  }

  async extractEntities(text, intent) {
    const entities = {};
    
    switch (intent.action) {
      case 'control_device':
        // 디바이스명 추출
        const deviceMatch = text.match(/^(.+?)\s*(를|을|의)?/);
        if (deviceMatch) {
          entities.device = this.resolveDeviceAlias(deviceMatch[1]);
        }
        
        // 액션 추출
        const actionMatch = text.match(/(켜|꺼|올려|내려|on|off|킬)/);
        if (actionMatch) {
          entities.action = this.normalizeAction(actionMatch[1]);
        }
        
        // 값 추출
        const valueMatch = text.match(/(\d+)\s*(도|%|단계)?/);
        if (valueMatch) {
          entities.value = parseInt(valueMatch[1]);
          entities.unit = valueMatch[2] || '';
        }
        break;
        
      case 'query_status':
        const queryDeviceMatch = text.match(/(.+?)\s*(의|이|가)/);
        if (queryDeviceMatch) {
          entities.device = this.resolveDeviceAlias(queryDeviceMatch[1]);
        }
        
        const propertyMatch = text.match(/(온도|습도|상태|밝기)/);
        if (propertyMatch) {
          entities.property = propertyMatch[1];
        }
        break;
        
      case 'activate_scene':
        const sceneMatch = text.match(/(.+?)\s*(모드|씬|장면)/);
        if (sceneMatch) {
          entities.scene = sceneMatch[1].trim();
        }
        break;
    }
    
    // 위치 정보 추출
    const locationMatch = text.match(/(거실|침실|주방|화장실|현관|베란다)/);
    if (locationMatch) {
      entities.location = locationMatch[1];
    }
    
    return entities;
  }

  resolveDeviceAlias(alias) {
    // 별칭을 실제 디바이스 ID로 변환
    const normalizedAlias = alias.trim().toLowerCase();
    
    // 직접 매칭
    if (this.deviceAliases.has(normalizedAlias)) {
      return this.deviceAliases.get(normalizedAlias);
    }
    
    // 부분 매칭
    for (const [key, deviceId] of this.deviceAliases) {
      if (key.includes(normalizedAlias) || normalizedAlias.includes(key)) {
        return deviceId;
      }
    }
    
    // 매칭 실패 시 원본 반환
    return alias;
  }

  normalizeAction(action) {
    const actionMap = {
      '켜': 'on',
      '킬': 'on',
      '꺼': 'off',
      '올려': 'increase',
      '내려': 'decrease',
      '설정': 'set'
    };
    
    return actionMap[action] || action;
  }

  async enrichWithContext(intent, entities) {
    // 사용자 컨텍스트 추가
    const context = await this.getContext();
    
    // 시간 기반 보강
    if (!entities.location && context.userLocation) {
      entities.location = context.userLocation;
    }
    
    // 이전 대화 컨텍스트
    if (!entities.device && context.lastDevice) {
      entities.device = context.lastDevice;
    }
    
    return {
      ...intent,
      entities,
      context: {
        time: new Date(),
        user_location: context.userLocation,
        weather: context.weather,
        previous_commands: context.history
      }
    };
  }

  async loadDeviceAliases() {
    // DB에서 디바이스 별칭 로드
    const devices = await Device.findAll({
      attributes: ['id', 'name', 'type', 'location']
    });
    
    devices.forEach(device => {
      // 기본 이름
      this.deviceAliases.set(device.name.toLowerCase(), device.id);
      
      // 위치 + 타입 조합
      if (device.location) {
        const locationAlias = `${device.location} ${device.type}`;
        this.deviceAliases.set(locationAlias.toLowerCase(), device.id);
      }
      
      // 커스텀 별칭 (사용자 정의)
      if (device.aliases) {
        device.aliases.forEach(alias => {
          this.deviceAliases.set(alias.toLowerCase(), device.id);
        });
      }
    });
  }
}

module.exports = new NLPService();
```

## 3. 고급 자동화 엔진

### 3.1 씬(Scene) 관리 시스템

```javascript
// backend/src/services/sceneService.js
const { Scene, SceneAction, Device } = require('../models');
const mqttService = require('./mqttService');
const automationEngine = require('./automationEngine');

class SceneService {
  constructor() {
    this.activeScenes = new Map();
    this.sceneQueue = [];
    this.initialize();
  }

  async initialize() {
    // 모든 씬 로드
    const scenes = await Scene.findAll({
      include: [SceneAction]
    });
    
    scenes.forEach(scene => {
      this.activeScenes.set(scene.id, scene);
    });
  }

  async createScene(sceneData) {
    const scene = await Scene.create({
      name: sceneData.name,
      description: sceneData.description,
      icon: sceneData.icon,
      triggers: sceneData.triggers || []
    });
    
    // 씬 액션 생성
    const actions = await Promise.all(
      sceneData.actions.map(action => 
        SceneAction.create({
          sceneId: scene.id,
          deviceId: action.deviceId,
          command: action.command,
          delay: action.delay || 0,
          order: action.order || 0
        })
      )
    );
    
    scene.SceneActions = actions;
    this.activeScenes.set(scene.id, scene);
    
    return scene;
  }

  async activateScene(sceneId, context = {}) {
    const scene = this.activeScenes.get(sceneId);
    if (!scene) {
      throw new Error(`Scene ${sceneId} not found`);
    }
    
    console.log(`Activating scene: ${scene.name}`);
    
    // 컨텍스트 기반 액션 조정
    const adjustedActions = await this.adjustActionsForContext(
      scene.SceneActions,
      context
    );
    
    // 액션 실행 계획 생성
    const executionPlan = this.createExecutionPlan(adjustedActions);
    
    // 병렬/순차 실행
    await this.executeScene(executionPlan);
    
    // 이벤트 발생
    this.emit('scene-activated', {
      sceneId,
      sceneName: scene.name,
      context,
      timestamp: new Date()
    });
    
    return {
      success: true,
      scene: scene.name,
      actionsExecuted: executionPlan.length
    };
  }

  async adjustActionsForContext(actions, context) {
    const adjusted = [];
    
    for (const action of actions) {
      let adjustedAction = { ...action.toJSON() };
      
      // 시간대별 조정
      if (context.timeOfDay) {
        adjustedAction = this.adjustForTimeOfDay(adjustedAction, context.timeOfDay);
      }
      
      // 날씨 기반 조정
      if (context.weather) {
        adjustedAction = this.adjustForWeather(adjustedAction, context.weather);
      }
      
      // 사용자 선호도 적용
      if (context.userPreferences) {
        adjustedAction = this.applyUserPreferences(adjustedAction, context.userPreferences);
      }
      
      adjusted.push(adjustedAction);
    }
    
    return adjusted;
  }

  adjustForTimeOfDay(action, timeOfDay) {
    // 조명 밝기 자동 조정
    if (action.command.type === 'brightness') {
      const brightnessMap = {
        morning: 70,
        afternoon: 100,
        evening: 50,
        night: 20
      };
      
      action.command.value = Math.min(
        action.command.value,
        brightnessMap[timeOfDay] || 100
      );
    }
    
    return action;
  }

  adjustForWeather(action, weather) {
    // 날씨에 따른 조정
    if (action.command.type === 'temperature' && weather.temperature) {
      // 외부 온도에 따라 에어컨/히터 설정 조정
      const offset = weather.temperature > 25 ? -2 : 2;
      action.command.value += offset;
    }
    
    if (action.command.type === 'blinds' && weather.condition === 'sunny') {
      // 맑은 날엔 블라인드 부분 차단
      action.command.value = Math.min(action.command.value, 50);
    }
    
    return action;
  }

  createExecutionPlan(actions) {
    // 액션을 순서와 지연시간에 따라 그룹화
    const groups = {};
    
    actions.forEach(action => {
      const groupKey = `${action.order}_${action.delay}`;
      if (!groups[groupKey]) {
        groups[groupKey] = [];
      }
      groups[groupKey].push(action);
    });
    
    // 실행 계획 생성
    return Object.entries(groups)
      .sort(([a], [b]) => {
        const [orderA, delayA] = a.split('_').map(Number);
        const [orderB, delayB] = b.split('_').map(Number);
        return orderA - orderB || delayA - delayB;
      })
      .map(([key, actions]) => ({
        delay: parseInt(key.split('_')[1]),
        actions
      }));
  }

  async executeScene(executionPlan) {
    for (const group of executionPlan) {
      // 지연 시간 대기
      if (group.delay > 0) {
        await new Promise(resolve => setTimeout(resolve, group.delay));
      }
      
      // 병렬 실행
      await Promise.all(
        group.actions.map(action => this.executeAction(action))
      );
    }
  }

  async executeAction(action) {
    try {
      await mqttService.sendCommand(action.deviceId, action.command);
      
      // 실행 로그
      await this.logExecution(action, 'success');
      
    } catch (error) {
      console.error(`Failed to execute action for device ${action.deviceId}:`, error);
      await this.logExecution(action, 'failed', error.message);
    }
  }
}

module.exports = new SceneService();
```

### 3.2 학습 기반 자동화

```javascript
// backend/src/services/adaptiveAutomation.js
const tf = require('@tensorflow/tfjs-node');
const { UserActivity, DeviceState, AutomationSuggestion } = require('../models');

class AdaptiveAutomationService {
  constructor() {
    this.model = null;
    this.patternBuffer = new Map();
    this.suggestionThreshold = 0.8;
    this.initialize();
  }

  async initialize() {
    // 사용자 행동 패턴 모델 로드
    try {
      this.model = await tf.loadLayersModel('file://./models/user_pattern_model/model.json');
    } catch (error) {
      console.log('Creating new pattern recognition model');
      this.model = this.createModel();
    }
    
    // 실시간 학습을 위한 버퍼 초기화
    this.startPatternCollection();
  }

  createModel() {
    const model = tf.sequential({
      layers: [
        tf.layers.dense({
          inputShape: [24 + 7 + 10], // 시간(24) + 요일(7) + 디바이스 상태(10)
          units: 64,
          activation: 'relu'
        }),
        tf.layers.dropout({ rate: 0.2 }),
        tf.layers.dense({
          units: 32,
          activation: 'relu'
        }),
        tf.layers.dense({
          units: 20, // 예측할 액션 수
          activation: 'softmax'
        })
      ]
    });
    
    model.compile({
      optimizer: 'adam',
      loss: 'categoricalCrossentropy',
      metrics: ['accuracy']
    });
    
    return model;
  }

  async collectUserActivity(userId, activity) {
    // 사용자 활동 수집
    await UserActivity.create({
      userId,
      timestamp: new Date(),
      deviceId: activity.deviceId,
      action: activity.action,
      context: {
        timeOfDay: this.getTimeOfDay(),
        dayOfWeek: new Date().getDay(),
        weather: await this.getWeatherContext(),
        previousActions: await this.getRecentActions(userId, 5)
      }
    });
    
    // 패턴 버퍼에 추가
    if (!this.patternBuffer.has(userId)) {
      this.patternBuffer.set(userId, []);
    }
    
    const buffer = this.patternBuffer.get(userId);
    buffer.push(activity);
    
    // 버퍼가 충분히 쌓이면 패턴 분석
    if (buffer.length >= 10) {
      await this.analyzePatterns(userId, buffer);
      this.patternBuffer.set(userId, []); // 버퍼 초기화
    }
  }

  async analyzePatterns(userId, activities) {
    // 시퀀스 패턴 찾기
    const patterns = this.findSequencePatterns(activities);
    
    // 시간 기반 패턴 찾기
    const timePatterns = this.findTimePatterns(activities);
    
    // 조건부 패턴 찾기
    const conditionalPatterns = await this.findConditionalPatterns(userId, activities);
    
    // 패턴 신뢰도 계산
    const suggestions = [];
    
    for (const pattern of [...patterns, ...timePatterns, ...conditionalPatterns]) {
      const confidence = await this.calculatePatternConfidence(pattern);
      
      if (confidence >= this.suggestionThreshold) {
        suggestions.push({
          userId,
          pattern,
          confidence,
          type: pattern.type
        });
      }
    }
    
    // 제안 생성
    await this.generateSuggestions(userId, suggestions);
  }

  findSequencePatterns(activities) {
    const patterns = [];
    const sequenceLength = 3;
    
    for (let i = 0; i <= activities.length - sequenceLength; i++) {
      const sequence = activities.slice(i, i + sequenceLength);
      
      // 반복되는 시퀀스 찾기
      const sequenceKey = sequence.map(a => `${a.deviceId}:${a.action}`).join('-');
      const occurrences = this.countSequenceOccurrences(activities, sequence);
      
      if (occurrences >= 3) {
        patterns.push({
          type: 'sequence',
          sequence: sequence,
          occurrences: occurrences,
          probability: occurrences / (activities.length - sequenceLength + 1)
        });
      }
    }
    
    return patterns;
  }

  findTimePatterns(activities) {
    const timePatterns = {};
    
    activities.forEach(activity => {
      const hour = new Date(activity.timestamp).getHours();
      const key = `${hour}:${activity.deviceId}:${activity.action}`;
      
      if (!timePatterns[key]) {
        timePatterns[key] = {
          type: 'time',
          hour: hour,
          deviceId: activity.deviceId,
          action: activity.action,
          count: 0,
          days: new Set()
        };
      }
      
      timePatterns[key].count++;
      timePatterns[key].days.add(new Date(activity.timestamp).toDateString());
    });
    
    // 일정 빈도 이상의 패턴만 반환
    return Object.values(timePatterns).filter(pattern => {
      const avgPerDay = pattern.count / pattern.days.size;
      return avgPerDay >= 0.7; // 70% 이상의 날에 발생
    });
  }

  async findConditionalPatterns(userId, activities) {
    const patterns = [];
    
    // 디바이스 상태 기반 패턴
    for (let i = 1; i < activities.length; i++) {
      const previous = activities[i - 1];
      const current = activities[i];
      
      // 이전 액션과 현재 액션 사이의 관계 분석
      const timeDiff = new Date(current.timestamp) - new Date(previous.timestamp);
      
      if (timeDiff < 5 * 60 * 1000) { // 5분 이내
        const condition = {
          type: 'conditional',
          trigger: {
            deviceId: previous.deviceId,
            action: previous.action
          },
          result: {
            deviceId: current.deviceId,
            action: current.action
          },
          avgDelay: timeDiff
        };
        
        // 이 조건부 패턴의 빈도 확인
        const frequency = await this.getConditionalFrequency(userId, condition);
        if (frequency > 0.6) {
          patterns.push({ ...condition, frequency });
        }
      }
    }
    
    return patterns;
  }

  async generateSuggestions(userId, patterns) {
    for (const pattern of patterns) {
      const suggestion = await this.createAutomationSuggestion(pattern);
      
      await AutomationSuggestion.create({
        userId,
        title: suggestion.title,
        description: suggestion.description,
        automationRule: suggestion.rule,
        confidence: pattern.confidence,
        patternType: pattern.type,
        status: 'pending'
      });
      
      // 사용자에게 알림
      await this.notifyUser(userId, suggestion);
    }
  }

  async createAutomationSuggestion(pattern) {
    switch (pattern.type) {
      case 'time':
        return {
          title: `매일 ${pattern.hour}시 자동 실행`,
          description: `${pattern.hour}시에 자동으로 ${pattern.deviceId}를 ${pattern.action}합니다.`,
          rule: {
            trigger: {
              type: 'time',
              time: `${pattern.hour}:00`,
              days: ['everyday']
            },
            action: {
              deviceId: pattern.deviceId,
              command: pattern.action
            }
          }
        };
        
      case 'sequence':
        return {
          title: '연속 동작 자동화',
          description: '자주 함께 사용하는 기기들을 한 번에 제어합니다.',
          rule: {
            trigger: {
              type: 'manual',
              name: 'custom_sequence'
            },
            actions: pattern.sequence.map((s, idx) => ({
              deviceId: s.deviceId,
              command: s.action,
              delay: idx * 1000
            }))
          }
        };
        
      case 'conditional':
        return {
          title: '조건부 자동화',
          description: `${pattern.trigger.deviceId}가 ${pattern.trigger.action}되면 ${pattern.result.deviceId}를 ${pattern.result.action}합니다.`,
          rule: {
            trigger: {
              type: 'device_state',
              deviceId: pattern.trigger.deviceId,
              condition: {
                state: pattern.trigger.action
              }
            },
            action: {
              deviceId: pattern.result.deviceId,
              command: pattern.result.action,
              delay: pattern.avgDelay
            }
          }
        };
    }
  }

  async predictNextAction(userId, currentContext) {
    // 현재 컨텍스트를 특징 벡터로 변환
    const features = await this.extractFeatures(currentContext);
    
    // 모델 예측
    const prediction = this.model.predict(features);
    const probabilities = await prediction.data();
    
    // 가장 확률이 높은 액션 반환
    const maxIndex = probabilities.indexOf(Math.max(...probabilities));
    const confidence = probabilities[maxIndex];
    
    if (confidence > 0.7) {
      return {
        action: this.indexToAction(maxIndex),
        confidence: confidence
      };
    }
    
    return null;
  }

  async extractFeatures(context) {
    const features = [];
    
    // 시간 특징 (24차원 - one-hot encoding)
    const hour = new Date().getHours();
    for (let i = 0; i < 24; i++) {
      features.push(i === hour ? 1 : 0);
    }
    
    // 요일 특징 (7차원)
    const day = new Date().getDay();
    for (let i = 0; i < 7; i++) {
      features.push(i === day ? 1 : 0);
    }
    
    // 디바이스 상태 특징 (10차원 - 주요 디바이스)
    const deviceStates = await this.getCurrentDeviceStates(context.userId);
    features.push(...deviceStates);
    
    return tf.tensor2d([features]);
  }
}

module.exports = new AdaptiveAutomationService();
```

## 4. Matter/Thread 통합

### 4.1 Matter 브릿지 구현

```javascript
// backend/src/services/matterBridge.js
const { MatterServer } = require('@project-chip/matter-node.js');
const { 
  DeviceTypes,
  OnOffCluster,
  LevelControlCluster,
  ColorControlCluster,
  TemperatureMeasurementCluster
} = require('@project-chip/matter-node.js/device');

class MatterBridge {
  constructor() {
    this.matterServer = null;
    this.deviceEndpoints = new Map();
    this.legacyDevices = new Map();
  }

  async initialize() {
    // Matter 서버 초기화
    this.matterServer = new MatterServer({
      port: 5540,
      discriminator: 3840,
      passcode: 20202021
    });

    // 커미셔닝 핸들러
    this.matterServer.on('commissioned', () => {
      console.log('Matter Bridge commissioned successfully');
    });

    await this.matterServer.start();
    console.log('Matter Bridge started');

    // 기존 디바이스 브릿징
    await this.bridgeExistingDevices();
  }

  async bridgeExistingDevices() {
    // V1에서 등록된 모든 디바이스 가져오기
    const devices = await Device.findAll({ where: { enabled: true } });

    for (const device of devices) {
      await this.bridgeDevice(device);
    }
  }

  async bridgeDevice(device) {
    console.log(`Bridging device: ${device.name} (${device.type})`);

    // 디바이스 타입에 따른 Matter Endpoint 생성
    const endpoint = await this.createMatterEndpoint(device);
    
    if (endpoint) {
      // Matter 서버에 엔드포인트 추가
      await this.matterServer.addEndpoint(endpoint);
      
      // 매핑 저장
      this.deviceEndpoints.set(device.id, endpoint);
      this.legacyDevices.set(endpoint.id, device);

      console.log(`Device ${device.name} bridged successfully`);
    }
  }

  async createMatterEndpoint(device) {
    let endpoint;

    switch (device.type) {
      case 'switch':
      case 'actuator':
        endpoint = await this.createOnOffLight(device);
        break;
      
      case 'dimmer':
        endpoint = await this.createDimmableLight(device);
        break;
      
      case 'rgb_light':
        endpoint = await this.createColorLight(device);
        break;
      
      case 'sensor':
        if (device.capabilities.includes('temperature')) {
          endpoint = await this.createTemperatureSensor(device);
        }
        break;
      
      default:
        console.warn(`Unsupported device type for Matter: ${device.type}`);
        return null;
    }

    return endpoint;
  }

  async createOnOffLight(device) {
    const endpoint = new Endpoint(DeviceTypes.ON_OFF_LIGHT, {
      id: this.getNextEndpointId(),
      clusters: {
        onOff: OnOffCluster({
          on: device.currentState?.on || false
        })
      }
    });

    // 명령 핸들러 설정
    endpoint.clusters.onOff.on.subscribe(async (value) => {
      console.log(`Matter command: Turn ${value ? 'on' : 'off'} ${device.name}`);
      
      // 레거시 디바이스로 명령 전달
      await mqttService.sendCommand(device.id, {
        action: 'set_state',
        state: value ? 'on' : 'off'
      });
    });

    // 상태 동기화
    mqttService.on(`device/${device.id}/state`, (state) => {
      endpoint.clusters.onOff.on.set(state.on);
    });

    return endpoint;
  }

  async createDimmableLight(device) {
    const endpoint = new Endpoint(DeviceTypes.DIMMABLE_LIGHT, {
      id: this.getNextEndpointId(),
      clusters: {
        onOff: OnOffCluster({
          on: device.currentState?.on || false
        }),
        levelControl: LevelControlCluster({
          currentLevel: device.currentState?.brightness || 100,
          minLevel: 1,
          maxLevel: 100
        })
      }
    });

    // 밝기 제어 핸들러
    endpoint.clusters.levelControl.currentLevel.subscribe(async (level) => {
      console.log(`Matter command: Set brightness to ${level} for ${device.name}`);
      
      await mqttService.sendCommand(device.id, {
        action: 'set_brightness',
        brightness: level
      });
    });

    return endpoint;
  }

  async createColorLight(device) {
    const endpoint = new Endpoint(DeviceTypes.COLOR_TEMPERATURE_LIGHT, {
      id: this.getNextEndpointId(),
      clusters: {
        onOff: OnOffCluster({
          on: device.currentState?.on || false
        }),
        levelControl: LevelControlCluster({
          currentLevel: device.currentState?.brightness || 100
        }),
        colorControl: ColorControlCluster({
          currentHue: device.currentState?.hue || 0,
          currentSaturation: device.currentState?.saturation || 0,
          colorMode: 0,
          colorCapabilities: 0x1F
        })
      }
    });

    // 색상 제어 핸들러
    endpoint.clusters.colorControl.currentHue.subscribe(async (hue) => {
      const saturation = endpoint.clusters.colorControl.currentSaturation.get();
      
      await mqttService.sendCommand(device.id, {
        action: 'set_color',
        hue: hue,
        saturation: saturation
      });
    });

    return endpoint;
  }

  async createTemperatureSensor(device) {
    const endpoint = new Endpoint(DeviceTypes.TEMPERATURE_SENSOR, {
      id: this.getNextEndpointId(),
      clusters: {
        temperatureMeasurement: TemperatureMeasurementCluster({
          measuredValue: (device.currentState?.temperature || 20) * 100,
          minMeasuredValue: -4000,  // -40°C
          maxMeasuredValue: 12500   // 125°C
        })
      }
    });

    // 센서 값 업데이트
    mqttService.on(`device/${device.id}/telemetry`, (data) => {
      if (data.temperature !== undefined) {
        endpoint.clusters.temperatureMeasurement.measuredValue.set(
          Math.round(data.temperature * 100)
        );
      }
    });

    return endpoint;
  }

  getNextEndpointId() {
    return this.deviceEndpoints.size + 1;
  }

  async removeDevice(deviceId) {
    const endpoint = this.deviceEndpoints.get(deviceId);
    if (endpoint) {
      await this.matterServer.removeEndpoint(endpoint);
      this.deviceEndpoints.delete(deviceId);
      this.legacyDevices.delete(endpoint.id);
    }
  }
}

module.exports = new MatterBridge();
```

### 4.2 Thread Border Router 설정

```javascript
// backend/src/services/threadService.js
const { exec } = require('child_process');
const util = require('util');
const execAsync = util.promisify(exec);

class ThreadService {
  constructor() {
    this.otbrAgentRunning = false;
    this.networkKey = null;
    this.panId = null;
  }

  async initialize() {
    // OpenThread Border Router 설정
    await this.setupOTBR();
    
    // Thread 네트워크 생성 또는 참가
    await this.setupThreadNetwork();
    
    // mDNS 광고 시작
    await this.startMdnsAdvertising();
  }

  async setupOTBR() {
    try {
      // OTBR 서비스 상태 확인
      const { stdout } = await execAsync('systemctl status otbr-agent');
      this.otbrAgentRunning = stdout.includes('active (running)');
      
      if (!this.otbrAgentRunning) {
        console.log('Starting OpenThread Border Router...');
        await execAsync('sudo systemctl start otbr-agent');
        this.otbrAgentRunning = true;
      }
      
      console.log('OpenThread Border Router is running');
    } catch (error) {
      console.error('Failed to setup OTBR:', error);
      throw error;
    }
  }

  async setupThreadNetwork() {
    try {
      // Thread 네트워크 설정 확인
      const { stdout: status } = await execAsync('sudo ot-ctl state');
      
      if (status.trim() === 'disabled') {
        // 새 Thread 네트워크 생성
        console.log('Creating new Thread network...');
        
        // 네트워크 파라미터 설정
        await execAsync('sudo ot-ctl dataset init new');
        await execAsync('sudo ot-ctl dataset networkname SmartHomeThread');
        await execAsync('sudo ot-ctl dataset channel 15');
        await execAsync('sudo ot-ctl dataset panid 0x1234');
        await execAsync('sudo ot-ctl dataset extpanid 1234567890123456');
        
        // 네트워크 키 생성
        await execAsync('sudo ot-ctl dataset networkkey 00112233445566778899aabbccddeeff');
        
        // 커밋 및 활성화
        await execAsync('sudo ot-ctl dataset commit active');
        await execAsync('sudo ot-ctl ifconfig up');
        await execAsync('sudo ot-ctl thread start');
        
        console.log('Thread network created successfully');
      } else {
        console.log(`Thread network already active: ${status.trim()}`);
      }
      
      // 네트워크 정보 저장
      await this.saveNetworkCredentials();
      
    } catch (error) {
      console.error('Failed to setup Thread network:', error);
      throw error;
    }
  }

  async saveNetworkCredentials() {
    try {
      const { stdout: dataset } = await execAsync('sudo ot-ctl dataset active -x');
      
      // 데이터셋을 파싱하여 저장
      this.activeDataset = dataset.trim();
      
      // QR 코드 생성을 위한 정보 추출
      const { stdout: eui64 } = await execAsync('sudo ot-ctl eui64');
      const { stdout: extaddr } = await execAsync('sudo ot-ctl extaddr');
      
      this.borderRouterInfo = {
        eui64: eui64.trim(),
        extaddr: extaddr.trim(),
        dataset: this.activeDataset
      };
      
      console.log('Thread network credentials saved');
    } catch (error) {
      console.error('Failed to save network credentials:', error);
    }
  }

  async startMdnsAdvertising() {
    // mDNS를 통한 Border Router 광고
    try {
      await execAsync(`
        sudo avahi-publish -s "SmartHome Thread Border Router" _meshcop._udp 49154 \
        "nn=SmartHomeThread" \
        "xp=\${EXTENDED_PAN_ID}" \
        "tv=1.3.0" \
        "sb=115200" \
        "at=0x00000000" \
        &
      `);
      
      console.log('mDNS advertising started');
    } catch (error) {
      console.error('Failed to start mDNS advertising:', error);
    }
  }

  async addThreadDevice(deviceEui) {
    try {
      // Thread 디바이스 커미셔닝
      console.log(`Commissioning Thread device: ${deviceEui}`);
      
      // Joiner 추가
      await execAsync(`sudo ot-ctl commissioner joiner add ${deviceEui} ABCDEFGH`);
      
      // 커미셔닝 시작
      await execAsync('sudo ot-ctl commissioner start');
      
      return {
        success: true,
        message: `Device ${deviceEui} commissioning started`,
        joinKey: 'ABCDEFGH'
      };
      
    } catch (error) {
      console.error('Failed to add Thread device:', error);
      return {
        success: false,
        error: error.message
      };
    }
  }

  async getNetworkTopology() {
    try {
      // Thread 네트워크 토폴로지 조회
      const { stdout: state } = await execAsync('sudo ot-ctl state');
      const { stdout: rloc16 } = await execAsync('sudo ot-ctl rloc16');
      const { stdout: neighbors } = await execAsync('sudo ot-ctl neighbor table');
      const { stdout: children } = await execAsync('sudo ot-ctl child table');
      
      return {
        role: state.trim(),
        rloc16: rloc16.trim(),
        neighbors: this.parseNeighborTable(neighbors),
        children: this.parseChildTable(children)
      };
      
    } catch (error) {
      console.error('Failed to get network topology:', error);
      return null;
    }
  }

  parseNeighborTable(output) {
    const lines = output.trim().split('\n').slice(1); // 헤더 제거
    return lines.map(line => {
      const parts = line.trim().split(/\s+/);
      return {
        rloc16: parts[0],
        linkQuality: parseInt(parts[1]),
        avgRssi: parseInt(parts[2]),
        lastRssi: parseInt(parts[3])
      };
    });
  }

  parseChildTable(output) {
    const lines = output.trim().split('\n').slice(1);
    return lines.map(line => {
      const parts = line.trim().split(/\s+/);
      return {
        rloc16: parts[0],
        timeout: parseInt(parts[1]),
        age: parseInt(parts[2]),
        avgRssi: parseInt(parts[3]),
        linkQuality: parseInt(parts[4])
      };
    });
  }

  async optimizeThreadNetwork() {
    // Thread 네트워크 최적화
    try {
      // 채널 스캔
      const { stdout: channelScan } = await execAsync('sudo ot-ctl scan');
      const bestChannel = this.findBestChannel(channelScan);
      
      if (bestChannel !== this.currentChannel) {
        console.log(`Switching to better channel: ${bestChannel}`);
        await execAsync(`sudo ot-ctl channel ${bestChannel}`);
      }
      
      // 라우팅 최적화
      await execAsync('sudo ot-ctl routerselectionjitter 120');
      
      return {
        optimized: true,
        newChannel: bestChannel
      };
      
    } catch (error) {
      console.error('Failed to optimize Thread network:', error);
      return { optimized: false, error: error.message };
    }
  }
}

module.exports = new ThreadService();
```

## 5. V2 통합 테스트 및 배포

### 5.1 음성 명령 E2E 테스트

```javascript
// test/e2e/voice-command.test.js
const request = require('supertest');
const app = require('../../src/app');
const fs = require('fs').promises;
const path = require('path');

describe('Voice Command E2E Test', () => {
  let authToken;
  let deviceId;

  beforeAll(async () => {
    // 테스트 환경 설정
    await setupTestEnvironment();
    
    // 테스트 사용자 로그인
    const auth = await login('test@example.com', 'password');
    authToken = auth.token;
    
    // 테스트 디바이스 생성
    const device = await createTestDevice(authToken, {
      name: '거실 조명',
      type: 'dimmer'
    });
    deviceId = device.id;
  });

  test('음성으로 조명 켜기', async () => {
    // 테스트 오디오 파일 로드
    const audioBuffer = await fs.readFile(
      path.join(__dirname, '../fixtures/turn_on_light.wav')
    );

    // 음성 명령 전송
    const response = await request(app)
      .post('/api/voice/command')
      .set('Authorization', `Bearer ${authToken}`)
      .send({
        audio: audioBuffer.toString('base64'),
        format: 'wav',
        sampleRate: 16000
      });

    expect(response.status).toBe(200);
    expect(response.body).toMatchObject({
      transcription: '거실 조명 켜줘',
      intent: {
        action: 'control_device',
        entities: {
          device: '거실 조명',
          action: 'on'
        }
      },
      response: '거실 조명을 켰습니다.',
      executed: true
    });

    // 디바이스 상태 확인
    const deviceState = await getDeviceState(authToken, deviceId);
    expect(deviceState.on).toBe(true);
  });

  test('복잡한 음성 명령 처리', async () => {
    const audioBuffer = await fs.readFile(
      path.join(__dirname, '../fixtures/complex_command.wav')
    );

    const response = await request(app)
      .post('/api/voice/command')
      .set('Authorization', `Bearer ${authToken}`)
      .send({
        audio: audioBuffer.toString('base64'),
        format: 'wav',
        sampleRate: 16000
      });

    expect(response.body).toMatchObject({
      transcription: '거실 조명을 50퍼센트로 설정하고 에어컨을 23도로 맞춰줘',
      intents: [
        {
          action: 'control_device',
          entities: {
            device: '거실 조명',
            action: 'set',
            value: 50,
            unit: '%'
          }
        },
        {
          action: 'control_device',
          entities: {
            device: '에어컨',
            action: 'set_temperature',
            value: 23,
            unit: '도'
          }
        }
      ],
      executed: true
    });
  });

  test('씬 활성화 음성 명령', async () => {
    // 테스트 씬 생성
    await createTestScene(authToken, {
      name: '영화 감상',
      actions: [
        { deviceId: 'light1', command: { brightness: 20 } },
        { deviceId: 'curtain1', command: { position: 'closed' } },
        { deviceId: 'tv1', command: { power: 'on' } }
      ]
    });

    const audioBuffer = await fs.readFile(
      path.join(__dirname, '../fixtures/activate_scene.wav')
    );

    const response = await request(app)
      .post('/api/voice/command')
      .set('Authorization', `Bearer ${authToken}`)
      .send({
        audio: audioBuffer.toString('base64')
      });

    expect(response.body).toMatchObject({
      transcription: '영화 감상 모드 시작해줘',
      intent: {
        action: 'activate_scene',
        entities: {
          scene: '영화 감상'
        }
      },
      response: '영화 감상 씬을 활성화했습니다.',
      executed: true
    });
  });
});
```

### 5.2 성능 모니터링 설정

```javascript
// backend/src/monitoring/performance.js
const prometheus = require('prom-client');
const { EventEmitter } = require('events');

class PerformanceMonitor extends EventEmitter {
  constructor() {
    super();
    this.register = new prometheus.Registry();
    this.setupMetrics();
  }

  setupMetrics() {
    // 음성 처리 메트릭
    this.voiceMetrics = {
      sttDuration: new prometheus.Histogram({
        name: 'voice_stt_duration_seconds',
        help: 'Speech-to-text processing duration',
        labelNames: ['model', 'language'],
        buckets: [0.1, 0.5, 1, 2, 5]
      }),
      
      ttsD turation: new prometheus.Histogram({
        name: 'voice_tts_duration_seconds',
        help: 'Text-to-speech processing duration',
        labelNames: ['voice', 'language'],
        buckets: [0.05, 0.1, 0.5, 1, 2]
      }),
      
      intentAccuracy: new prometheus.Gauge({
        name: 'voice_intent_accuracy',
        help: 'Intent recognition accuracy',
        labelNames: ['intent_type']
      }),
      
      commandLatency: new prometheus.Histogram({
        name: 'voice_command_latency_seconds',
        help: 'End-to-end voice command latency',
        buckets: [0.5, 1, 2, 3, 5, 10]
      })
    };

    // 자동화 메트릭
    this.automationMetrics = {
      executionTime: new prometheus.Histogram({
        name: 'automation_execution_seconds',
        help: 'Automation rule execution time',
        labelNames: ['rule_type', 'complexity'],
        buckets: [0.01, 0.05, 0.1, 0.5, 1]
      }),
      
      triggerCount: new prometheus.Counter({
        name: 'automation_triggers_total',
        help: 'Total automation triggers',
        labelNames: ['trigger_type', 'success']
      }),
      
      patternDetection: new prometheus.Gauge({
        name: 'automation_patterns_detected',
        help: 'Number of behavior patterns detected',
        labelNames: ['pattern_type']
      })
    };

    // Matter/Thread 메트릭
    this.protocolMetrics = {
      matterDevices: new prometheus.Gauge({
        name: 'matter_devices_connected',
        help: 'Number of Matter devices connected'
      }),
      
      threadNodes: new prometheus.Gauge({
        name: 'thread_network_nodes',
        help: 'Number of Thread network nodes',
        labelNames: ['node_type']
      }),
      
      bridgeLatency: new prometheus.Histogram({
        name: 'protocol_bridge_latency_seconds',
        help: 'Protocol translation latency',
        labelNames: ['from_protocol', 'to_protocol'],
        buckets: [0.001, 0.005, 0.01, 0.05, 0.1]
      })
    };

    // 모든 메트릭 등록
    Object.values(this.voiceMetrics).forEach(metric => this.register.registerMetric(metric));
    Object.values(this.automationMetrics).forEach(metric => this.register.registerMetric(metric));
    Object.values(this.protocolMetrics).forEach(metric => this.register.registerMetric(metric));
  }

  recordVoiceCommand(startTime, endTime, stages) {
    const totalDuration = (endTime - startTime) / 1000;
    
    this.voiceMetrics.commandLatency.observe(totalDuration);
    
    if (stages.stt) {
      this.voiceMetrics.sttDuration
        .labels({ model: 'whisper-small', language: 'ko' })
        .observe(stages.stt.duration);
    }
    
    if (stages.tts) {
      this.voiceMetrics.ttsDuration
        .labels({ voice: 'ko_KR-kss', language: 'ko' })
        .observe(stages.tts.duration);
    }
  }

  recordAutomationExecution(rule, startTime, endTime, success) {
    const duration = (endTime - startTime) / 1000;
    
    this.automationMetrics.executionTime
      .labels({
        rule_type: rule.type,
        complexity: rule.actions.length > 5 ? 'complex' : 'simple'
      })
      .observe(duration);
    
    this.automationMetrics.triggerCount
      .labels({
        trigger_type: rule.trigger.type,
        success: success ? 'true' : 'false'
      })
      .inc();
  }

  updateProtocolMetrics(matterCount, threadTopology) {
    this.protocolMetrics.matterDevices.set(matterCount);
    
    if (threadTopology) {
      this.protocolMetrics.threadNodes
        .labels({ node_type: 'router' })
        .set(threadTopology.routers || 0);
      
      this.protocolMetrics.threadNodes
        .labels({ node_type: 'end_device' })
        .set(threadTopology.endDevices || 0);
    }
  }

  getMetrics() {
    return this.register.metrics();
  }
}

module.exports = new PerformanceMonitor();
```

## 6. V2 배포 가이드

### 6.1 Docker Compose 업데이트

```yaml
# docker-compose.v2.yml
version: '3.8'

services:
  # 기존 서비스들 (V1)
  postgres:
    image: postgres:15
    # ... (V1과 동일)

  redis:
    image: redis:7-alpine
    # ... (V1과 동일)

  mosquitto:
    image: eclipse-mosquitto:2
    # ... (V1과 동일)

  # V2 추가 서비스
  whisper-service:
    build: ./services/whisper
    volumes:
      - ./models/whisper:/models
    environment:
      - MODEL_PATH=/models/whisper-small-ko
      - COMPUTE_TYPE=int8
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  piper-tts:
    build: ./services/piper
    volumes:
      - ./models/piper:/models
    environment:
      - VOICE_MODEL=/models/ko_KR-kss-medium.onnx
    ports:
      - "5003:5003"

  edge-ai-server:
    build: ./services/edge-ai
    volumes:
      - ./models:/models
    environment:
      - ONNX_MODEL_PATH=/models
    ports:
      - "5004:5004"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # GPU 사용 시

  matter-bridge:
    build: ./services/matter-bridge
    network_mode: host  # Matter는 로컬 네트워크 접근 필요
    privileged: true
    volumes:
      - ./data/matter:/data
    environment:
      - MATTER_PORT=5540
      - MATTER_DISCRIMINATOR=3840

  thread-border-router:
    image: openthread/otbr:latest
    network_mode: host
    privileged: true
    volumes:
      - /dev:/dev
    environment:
      - OTBR_AGENT_OPTS=-I wpan0 spinel+hdlc+uart:///dev/ttyACM0

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/dashboards:/etc/grafana/provisioning/dashboards
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

volumes:
  postgres_data:
  prometheus_data:
  grafana_data:
  mosquitto_data:
```

### 6.2 V2 시작 스크립트

```bash
#!/bin/bash
# deploy-v2.sh

echo "🚀 Starting IoT Platform V2 Deployment..."

# 1. 환경 확인
check_requirements() {
    echo "Checking requirements..."
    
    # Docker 확인
    if ! command -v docker &> /dev/null; then
        echo "❌ Docker not found. Please install Docker."
        exit 1
    fi
    
    # 하드웨어 확인
    if [ -e /dev/ttyACM0 ]; then
        echo "✅ Thread radio detected"
    else
        echo "⚠️ Thread radio not found. Thread features will be disabled."
    fi
    
    # 모델 파일 확인
    if [ ! -f "./models/whisper/whisper-small-ko/model.bin" ]; then
        echo "📥 Downloading Whisper model..."
        ./scripts/download-models.sh
    fi
}

# 2. 데이터베이스 마이그레이션
migrate_database() {
    echo "Running database migrations..."
    cd backend
    npm run migrate:v2
    cd ..
}

# 3. V2 서비스 시작
start_services() {
    echo "Starting V2 services..."
    
    # 기존 서비스 유지하며 V2 추가
    docker-compose -f docker-compose.yml -f docker-compose.v2.yml up -d
    
    # 헬스 체크
    sleep 10
    ./scripts/health-check.sh
}

# 4. Matter 네트워크 초기화
setup_matter() {
    echo "Initializing Matter network..."
    
    # Matter 커미셔닝 정보 생성
    docker exec matter-bridge node /app/scripts/generate-qr-code.js
}

# 5. AI 스피커 펌웨어 업데이트
update_speaker_firmware() {
    echo "Checking AI speaker firmware updates..."
    
    # OTA 업데이트 트리거
    curl -X POST http://localhost:3000/api/ota/trigger \
        -H "Content-Type: application/json" \
        -d '{
            "deviceType": "ai_speaker",
            "version": "2.0.0",
            "features": ["wake_word", "local_stt", "matter"]
        }'
}

# 메인 실행
check_requirements
migrate_database
start_services
setup_matter
update_speaker_firmware

echo "✅ V2 deployment completed!"
echo "📊 Monitoring dashboard: http://localhost:3001"
echo "🎙️ Voice service ready on AI speakers"
echo "🏠 Matter bridge running on port 5540"
```

## 7. V2 완료 체크리스트

### 기능 완성도
- [ ] Wake Word Detection 정확도 > 95%
- [ ] 한국어 음성 인식 정확도 > 90%
- [ ] 음성 명령 응답 시간 < 2초
- [ ] 10개 이상 동시 음성 처리
- [ ] 자동화 패턴 학습 동작
- [ ] Matter 디바이스 페어링
- [ ] Thread 메시 네트워크 구성

### 성능 목표
- 음성 처리 지연: < 1.5초 (로컬)
- 자동화 실행 시간: < 100ms
- Matter 브릿지 지연: < 50ms
- 동시 연결 디바이스: 50개+

### 보안 강화
- [ ] 음성 데이터 로컬 처리
- [ ] Matter 보안 인증
- [ ] Thread 네트워크 암호화
- [ ] 프라이버시 설정 UI

이제 V2가 완성되었습니다! V3로 진행하시겠습니까?