# AI 스피커 IoT 서비스 아키텍처 개발자 문서

## 🎯 프로젝트 개요

우리가 만드는 AI 스피커는 단순한 명령 수행 도구가 아닌, **사용자와 함께 생활하는 지능형 동반자**입니다. 사용자의 행동 패턴을 학습하고, 필요한 순간에 먼저 말을 걸며, 자연스러운 대화를 통해 일상을 도와줍니다.

### 핵심 차별점
- **선제적 대화(Proactive Interaction)**: "좋은 아침이에요! 오늘은 비가 올 예정이니 우산 챙기세요"
- **컨텍스트 이해(Contextual Understanding)**: 대화의 맥락을 기억하고 자연스럽게 이어감
- **플러그인 확장성(Plugin Architecture)**: 새로운 기능을 플러그인으로 쉽게 추가

---

## 📋 MVP 아키텍처 (3개월 목표)

### 1. Device Layer (라즈베리파이)

**주요 컴포넌트와 역할:**

```python
# Wake Word Detection 예시
def detect_wake_word(audio_stream):
    if porcupine.process(audio_stream) >= 0:
        # "헤이 스피커" 감지됨
        mqtt_client.publish("device/wake", {"timestamp": now()})
```

- **Audio I/O**: 마이크로 음성을 수집하고 스피커로 재생
- **Wake Word Detection**: 로컬에서 트리거 워드 감지 (네트워크 없어도 동작)
- **Motion Sensor**: 사용자 움직임 감지하여 선제적 대화 트리거
- **MQTT Client**: 모든 이벤트를 백엔드로 전송

### 2. Backend Services (Spring Boot)

**핵심 서비스 흐름:**

```java
// Dialog Manager의 핵심 로직
@Service
public class DialogManager {
    public DialogResponse process(UserInput input) {
        // 1. 현재 대화 컨텍스트 로드
        Context context = contextEngine.getContext(input.getUserId());
        
        // 2. 의도 파악 (Dialogflow 연동)
        Intent intent = nlpService.analyzeIntent(input.getText());
        
        // 3. 적절한 플러그인 선택 및 실행
        Plugin plugin = pluginManager.selectPlugin(intent);
        PluginResponse response = plugin.execute(context, intent);
        
        // 4. 컨텍스트 업데이트
        contextEngine.updateContext(input.getUserId(), response);
        
        return response;
    }
}
```

**플러그인 시스템:**
- 각 기능은 독립적인 플러그인으로 구현
- 인터페이스만 구현하면 자동으로 시스템에 통합
- MVP에는 Weather, Time, Greeting 플러그인 포함

### 3. AI/ML Services

초기에는 Google Cloud 서비스를 활용하여 빠르게 프로토타입 구축:
- **STT**: 음성을 텍스트로 변환
- **Dialogflow**: 의도와 엔티티 추출
- **TTS**: 응답을 자연스러운 음성으로 변환

### 4. 데이터 흐름 시나리오

**아침 인사 시나리오:**
1. Motion Sensor가 아침 7시에 움직임 감지
2. MQTT로 "user_motion" 이벤트 전송
3. Context Engine이 "아침 + 첫 움직임" 패턴 인식
4. Dialog Manager가 Greeting Plugin 호출
5. Weather Plugin도 함께 호출하여 날씨 정보 포함
6. "좋은 아침이에요! 오늘은 맑은 날씨네요" 음성 출력

---

## 🚀 확장 IoT 서비스 아키텍처

### 1. Edge Computing Layer

MVP의 라즈베리파이가 강력한 엣지 허브로 진화:
- **Local AI Engine**: 인터넷 연결 없이도 기본 대화 가능
- **Device Controller**: Matter/Thread 프로토콜로 모든 스마트 기기 통합
- **Edge TPU**: 로컬에서 AI 모델 실행으로 응답 속도 향상

### 2. Microservices Architecture

각 서비스가 독립적으로 확장 가능한 구조:

```yaml
# Kubernetes 배포 예시
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dialog-orchestrator
spec:
  replicas: 3  # 트래픽에 따라 자동 스케일링
  template:
    spec:
      containers:
      - name: dialog-service
        image: ai-speaker/dialog:v2.0
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
```

### 3. 이벤트 기반 아키텍처

Apache Kafka를 중심으로 모든 이벤트가 흐르는 구조:

```java
// 이벤트 발행 예시
@EventListener
public void onUserActivity(UserActivityEvent event) {
    // 여러 서비스가 동시에 이 이벤트를 처리
    kafkaTemplate.send("user-activity", event);
}

// Context Service에서 구독
@KafkaListener(topics = "user-activity")
public void handleUserActivity(UserActivityEvent event) {
    // 사용자 패턴 학습 및 컨텍스트 업데이트
    updateUserContext(event);
}
```

### 4. 플러그인 생태계

서드파티 개발자도 플러그인을 만들 수 있는 SDK 제공:

```java
// 커스텀 플러그인 예시
@Plugin(name = "smart-recipe")
public class SmartRecipePlugin implements ConversationPlugin {
    @Override
    public PluginResponse process(Context context, Intent intent) {
        // 냉장고 상태 확인
        List<Food> available = getFridgeContents(context.getUserId());
        
        // AI로 레시피 추천
        Recipe recipe = recommendRecipe(available);
        
        return PluginResponse.builder()
            .speech("냉장고에 있는 재료로 " + recipe.getName() + " 만들어보는 건 어떠세요?")
            .action(DisplayRecipeAction.of(recipe))
            .build();
    }
}
```

### 5. AI/ML Platform

자체 AI 모델 학습 및 배포 파이프라인:
- **MLflow**: 모델 버전 관리 및 A/B 테스트
- **Kubeflow**: 대규모 모델 학습 자동화
- **Personalization Engine**: 사용자별 맞춤 응답 생성

---

## 🔄 핵심 데이터 흐름

### 1. 실시간 대화 처리 (< 300ms 목표)
```
사용자 음성 → Edge STT → Intent 분석 → 
Plugin 실행 → Response 생성 → Edge TTS → 음성 출력
```

### 2. 선제적 대화 트리거
```
센서 데이터 → Pattern 인식 → Context 확인 → 
Proactive Rule 매칭 → 대화 시작
```

### 3. 학습 및 개선 루프
```
사용자 피드백 → Analytics 수집 → Pattern 분석 → 
Model 재학습 → A/B 테스트 → 배포
```

---

## 👨‍💻 개발 시작 가이드

### 1. MVP 개발 환경 설정

```bash
# 1. 백엔드 서비스 실행
cd backend
./gradlew bootRun

# 2. Redis 실행 (Docker)
docker run -d -p 6379:6379 redis:alpine

# 3. 라즈베리파이 클라이언트
cd raspberry-pi
pip install -r requirements.txt
python main.py
```

### 2. 첫 번째 플러그인 만들기

```java
@Component
public class MyFirstPlugin implements ConversationPlugin {
    @Override
    public String getName() {
        return "my-plugin";
    }
    
    @Override
    public List<String> getSupportedIntents() {
        return Arrays.asList("greeting", "farewell");
    }
    
    @Override
    public PluginResponse process(Context context, Intent intent) {
        // 여기에 로직 구현
        return PluginResponse.of("안녕하세요!");
    }
}
```

### 3. 테스트 및 디버깅

```bash
# 단위 테스트
./gradlew test

# 통합 테스트 (Docker Compose 사용)
docker-compose up -d
./gradlew integrationTest

# 로그 확인
kubectl logs -f deployment/dialog-orchestrator
```

---

## 📈 성능 목표 및 모니터링

### MVP 목표
- 음성 응답 시간: < 2초
- 동시 사용자: 10명
- 가용성: 95%

### 확장 서비스 목표
- 음성 응답 시간: < 300ms (Edge AI 활용)
- 동시 사용자: 10,000명
- 가용성: 99.9%

### 모니터링 대시보드
- **Grafana**: 실시간 시스템 메트릭
- **ELK Stack**: 대화 로그 분석
- **Custom Dashboard**: 사용자 행동 패턴 시각화

---

## 🎓 학습 로드맵

### 1단계 (현재 수준에서 시작)
- Spring Boot 심화 (WebFlux, Cloud)
- Docker & Docker Compose
- MQTT 프로토콜 이해

### 2단계 (MVP 개발 중)
- Kubernetes 기초
- Apache Kafka
- Redis 고급 기능

### 3단계 (확장 서비스)
- 분산 시스템 설계
- ML 파이프라인 구축
- Edge Computing

---

## 💡 개발 팁

1. **작게 시작하세요**: Weather Plugin 하나만 완벽하게 만들어보세요
2. **로그를 충분히 남기세요**: 대화 흐름을 추적할 수 있어야 합니다
3. **테스트를 작성하세요**: 특히 플러그인 인터페이스는 철저히 테스트
4. **사용자 피드백을 수집하세요**: 실제 사용 패턴이 가장 중요합니다

이 문서는 프로젝트가 진화함에 따라 계속 업데이트됩니다. 질문이나 제안사항이 있다면 언제든 공유해주세요!