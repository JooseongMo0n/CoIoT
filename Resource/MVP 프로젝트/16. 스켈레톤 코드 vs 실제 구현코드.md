# 스켈레톤 코드 vs 실제 구현 코드 비교

## 현재 스켈레톤 코드 상태

```
┌─────────────────────────────────────────────────────────┐
│                    전체 MVP 구현 범위                      │
├─────────────────────────────────────────────────────────┤
│ ██████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░ 35%  │
└─────────────────────────────────────────────────────────┘

구조 설계    ████████████████████ 100%
인터페이스   ██████████████████░░  90%
설정 파일    ████████████████░░░░  80%
도메인 모델  ██████████████░░░░░░  70%
API 정의     ████████████░░░░░░░░  60%
기본 로직    ████░░░░░░░░░░░░░░░░  20%
통합 테스트  ███░░░░░░░░░░░░░░░░░  15%
에러 처리    ██░░░░░░░░░░░░░░░░░░  10%
```

## 주요 차이점 분석

### 1. DialogManager 비교

**현재 스켈레톤 코드:**
```java
public DialogResponse processUserInput(String userId, String text, String sessionId) {
    // 1. 컨텍스트 로드/생성
    ConversationContext context = contextEngine.getOrCreateContext(userId, sessionId);
    
    // 2. 의도 분석
    Intent intent = dialogflowService.analyzeIntent(text, context);
    
    // 3. 플러그인 선택 및 실행
    ConversationPlugin plugin = pluginManager.selectPlugin(intent, context);
    PluginResponse pluginResponse = plugin.execute(intent, context);
    
    // ... 단순한 흐름
}
```

**실제 구현 필요 코드:**
```java
public DialogResponse processUserInput(String userId, String text, String sessionId) {
    try {
        // 입력 검증
        validateInput(userId, text, sessionId);
        
        // 사용자 상태 확인
        UserStatus userStatus = userService.checkUserStatus(userId);
        if (userStatus.isBlocked()) {
            throw new UserBlockedException("User is blocked");
        }
        
        // Rate Limiting
        rateLimiter.checkLimit(userId);
        
        // 컨텍스트 로드 with retry
        ConversationContext context = retryTemplate.execute(ctx -> 
            contextEngine.getOrCreateContext(userId, sessionId)
        );
        
        // 감정 분석 (선택적)
        EmotionAnalysis emotion = emotionAnalyzer.analyze(text);
        context.setCurrentEmotion(emotion);
        
        // 의도 분석 with fallback
        Intent intent;
        try {
            intent = dialogflowService.analyzeIntent(text, context);
        } catch (DialogflowException e) {
            logger.warn("Dialogflow failed, using local NLU", e);
            intent = localNLUService.analyzeIntent(text);
        }
        
        // 멀티 플러그인 처리
        List<ConversationPlugin> candidatePlugins = pluginManager.selectPlugins(intent, context);
        
        PluginResponse bestResponse = null;
        double highestConfidence = 0.0;
        
        // 병렬 처리 with timeout
        List<CompletableFuture<PluginResponse>> futures = candidatePlugins.stream()
            .map(plugin -> CompletableFuture.supplyAsync(() -> 
                executePluginWithTimeout(plugin, intent, context), executorService))
            .collect(Collectors.toList());
        
        // 결과 수집
        List<PluginResponse> responses = futures.stream()
            .map(future -> {
                try {
                    return future.get(2, TimeUnit.SECONDS);
                } catch (Exception e) {
                    logger.error("Plugin execution failed", e);
                    return null;
                }
            })
            .filter(Objects::nonNull)
            .collect(Collectors.toList());
        
        // 최적 응답 선택
        bestResponse = selectBestResponse(responses, context);
        
        // 응답 후처리
        bestResponse = postProcessResponse(bestResponse, context, emotion);
        
        // 대화 기록 저장 (비동기)
        CompletableFuture.runAsync(() -> {
            saveDialogHistory(userId, sessionId, text, bestResponse);
            updateUserMetrics(userId, intent);
            publishAnalyticsEvent(userId, intent, bestResponse);
        });
        
        // 캐시 업데이트
        updateResponseCache(userId, text, bestResponse);
        
        return DialogResponse.builder()
            .speech(bestResponse.getSpeech())
            .displayText(bestResponse.getDisplayText())
            .intent(intent.getName())
            .confidence(bestResponse.getConfidence())
            .actions(bestResponse.getActions())
            .contextUpdate(bestResponse.getContextUpdate())
            .processingTime(System.currentTimeMillis() - startTime)
            .build();
            
    } catch (UserBlockedException e) {
        return createBlockedUserResponse();
    } catch (RateLimitExceededException e) {
        return createRateLimitResponse();
    } catch (Exception e) {
        logger.error("Dialog processing failed", e);
        errorReporter.report(e, userId, text);
        return createErrorResponse(e);
    }
}
```

### 2. Plugin 실행 차이

**스켈레톤:**
```java
public PluginResponse execute(Intent intent, Context context) {
    String location = extractLocation(intent, context);
    WeatherData weather = weatherApiClient.getWeather(location);
    return buildWeatherResponse(weather);
}
```

**실제 구현:**
```java
public PluginResponse execute(Intent intent, Context context) {
    StopWatch stopWatch = new StopWatch();
    stopWatch.start();
    
    try {
        // 권한 확인
        if (!hasPermission(context.getUserId(), "weather.query")) {
            return createNoPermissionResponse();
        }
        
        // 위치 추출 with validation
        String location = extractLocation(intent, context);
        if (!isValidLocation(location)) {
            return createInvalidLocationResponse(location);
        }
        
        // 캐시 확인
        String cacheKey = generateCacheKey("weather", location);
        WeatherData cachedData = cache.get(cacheKey, WeatherData.class);
        
        if (cachedData != null && !cachedData.isExpired()) {
            metrics.incrementCacheHit("weather");
            return buildWeatherResponse(cachedData, true);
        }
        
        // API 호출 with circuit breaker
        WeatherData weather;
        try {
            weather = circuitBreaker.executeSupplier(() -> 
                weatherApiClient.getWeather(location)
            );
            
            // 캐시 저장
            cache.put(cacheKey, weather, Duration.ofMinutes(10));
            
        } catch (CircuitBreakerOpenException e) {
            // Fallback 데이터 사용
            weather = weatherFallbackService.getLastKnownWeather(location);
            if (weather == null) {
                return createServiceUnavailableResponse();
            }
        }
        
        // 사용자 선호도 반영
        UserPreferences prefs = context.getUserProfile().getPreferences();
        String unit = prefs.getTemperatureUnit(); // C or F
        weather = convertTemperatureUnit(weather, unit);
        
        // 응답 생성
        PluginResponse response = buildWeatherResponse(weather, false);
        
        // 추가 정보 (옷차림 추천 등)
        if (intent.getParameters().containsKey("include_recommendation")) {
            ClothingRecommendation recommendation = 
                clothingRecommender.recommend(weather, context.getUserProfile());
            response = enrichResponseWithRecommendation(response, recommendation);
        }
        
        // 메트릭 기록
        stopWatch.stop();
        metrics.recordPluginExecution("weather", stopWatch.getTotalTimeMillis());
        
        return response;
        
    } catch (Exception e) {
        logger.error("Weather plugin execution failed", e);
        metrics.incrementPluginError("weather");
        
        // Graceful degradation
        return createGenericWeatherErrorResponse();
        
    } finally {
        MDC.remove("plugin");
    }
}
```

### 3. Raspberry Pi 클라이언트 차이

**스켈레톤:**
```python
async def _handle_voice_interaction(self):
    audio_data = self.microphone.record(duration=5.0)
    response = await self._send_audio_to_server(audio_data)
    await self.speaker.speak_async(response['speech'])
```

**실제 구현:**
```python
async def _handle_voice_interaction(self):
    try:
        # LED 표시
        self.led_controller.set_listening()
        
        # 노이즈 레벨 체크
        noise_level = self.microphone.get_ambient_noise_level()
        if noise_level > self.config['noise_threshold']:
            await self._handle_noisy_environment()
        
        # VAD (Voice Activity Detection)
        vad = VoiceActivityDetector()
        audio_chunks = []
        silence_duration = 0
        max_recording_time = 10.0
        
        start_time = time.time()
        
        while silence_duration < 1.5 and (time.time() - start_time) < max_recording_time:
            chunk = self.microphone.read_chunk()
            
            if vad.is_speech(chunk):
                audio_chunks.append(chunk)
                silence_duration = 0
            else:
                silence_duration += 0.1
                if audio_chunks:  # 이미 음성이 시작된 경우만
                    audio_chunks.append(chunk)
        
        if not audio_chunks:
            self.speaker.play_sound('no_speech_detected.wav')
            return
        
        # 오디오 전처리
        audio_data = np.concatenate(audio_chunks)
        audio_data = self.audio_processor.remove_noise(audio_data, noise_level)
        audio_data = self.audio_processor.normalize(audio_data)
        
        # 로컬 STT 시도 (빠른 응답)
        if self.local_stt_enabled:
            local_text = await self.local_stt.transcribe(audio_data)
            if local_text and self._is_simple_command(local_text):
                response = await self._handle_local_command(local_text)
                if response:
                    await self.speaker.speak_async(response)
                    return
        
        # 서버 전송
        try:
            response = await self._send_audio_to_server(
                audio_data,
                metadata={
                    'noise_level': noise_level,
                    'local_transcript': local_text if 'local_text' in locals() else None,
                    'device_state': self.device_manager.get_current_state()
                }
            )
            
            # 응답 처리
            if response.get('requires_confirmation'):
                confirmed = await self._get_user_confirmation(response['confirmation_prompt'])
                if not confirmed:
                    return
            
            # TTS with emotion
            emotion = response.get('emotion', 'neutral')
            await self.speaker.speak_with_emotion(response['speech'], emotion)
            
            # 액션 실행
            if 'actions' in response:
                await self._execute_actions_with_feedback(response['actions'])
            
        except NetworkException:
            # 오프라인 모드
            await self._handle_offline_mode(audio_data)
            
    except Exception as e:
        logger.error(f"Voice interaction failed: {e}")
        self.led_controller.set_error()
        self.speaker.play_sound('error.wav')
        
        # 에러 리포팅
        await self.error_reporter.report(e, context={
            'audio_length': len(audio_data) if 'audio_data' in locals() else 0,
            'noise_level': noise_level if 'noise_level' in locals() else 0
        })
```

## 완성도 차이 요약

| 컴포넌트 | 스켈레톤 | 실제 구현 필요 | 주요 차이점 |
|---------|---------|--------------|------------|
| 에러 처리 | try-catch 기본 | 세분화된 예외처리, 복구 전략 | Graceful degradation, Circuit breaker |
| 검증 로직 | 거의 없음 | 모든 입력/출력 검증 | 보안, 데이터 무결성 |
| 성능 최적화 | 없음 | 캐싱, 병렬처리, 비동기 | 응답시간, 리소스 효율성 |
| 모니터링 | 기본 로깅 | 메트릭, 추적, 알림 | 운영 가시성 |
| 확장성 | 단일 인스턴스 | 분산 처리, 스케일링 | 고가용성 |